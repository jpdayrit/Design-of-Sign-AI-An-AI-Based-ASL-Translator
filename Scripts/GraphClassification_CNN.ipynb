{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphClassification_CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT6KWN4hOJuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "DATADIR = \"/content/drive/My Drive/PseudoDataTrain\"\n",
        "\n",
        "CATEGORIES = [\"type_1\", \"type_2\", \"type_3\"]\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G02qicwxOMbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = []\n",
        "IMG_SIZE = 450\n",
        "\n",
        "def create_training_data():\n",
        "  for category in CATEGORIES:  \n",
        "    path = os.path.join(DATADIR,category)  \n",
        "    class_num = CATEGORIES.index(category)  # if 0, type 1 data; 1, type 2 data; 2, type 3 data. \n",
        "    for img in os.listdir(path):  \n",
        "        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "        training_data.append([new_array, class_num])\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "print(len(training_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IqcbfXlOL4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR_VAL = \"/content/drive/My Drive/PseudoDataValid\"\n",
        "\n",
        "validation_data = []\n",
        "\n",
        "def create_validation_data():\n",
        "  for category in CATEGORIES:  \n",
        "    path = os.path.join(DATADIR_VAL,category)  \n",
        "    class_num = CATEGORIES.index(category)  # if 0, type 1 data; 1, type 2 data; 3, type 3 data. \n",
        "    for img in os.listdir(path):  \n",
        "        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "        validation_data.append([new_array, class_num])\n",
        "\n",
        "create_validation_data()\n",
        "\n",
        "print(len(validation_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb8yJwK--1h8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "\n",
        "random.shuffle(training_data)\n",
        "random.shuffle(validation_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4N1U4RZtHuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "X_val = []\n",
        "y_val = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2vJf9TkwBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for features, label in training_data:\n",
        "  X.append(features)\n",
        "  y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "for features, label in validation_data:\n",
        "  X_val.append(features)\n",
        "  y_val.append(label)\n",
        "\n",
        "X_val = np.array(X_val).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VFCKTSJkwIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open('X.pickle', 'wb')\n",
        "pickle.dump(X, pickle_out)  # dumps X into pickle_out\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('y.pickle', 'wb')\n",
        "pickle.dump(y, pickle_out)  # dumps y into pickle_out\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('X_val.pickle', 'wb')\n",
        "pickle.dump(X_val, pickle_out)  # dumps X_val into pickle_out\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open('y_val.pickle', 'wb')\n",
        "pickle.dump(y_val, pickle_out)  # dumps y_val into pickle_out\n",
        "pickle_out.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbt-hzDkqQoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import pickle\n",
        "\n",
        "train_images = pickle.load(open('X.pickle', 'rb'))  # the data\n",
        "train_labels = pickle.load(open('y.pickle', 'rb'))  # labels for each data\n",
        "\n",
        "test_images = pickle.load(open('X_val.pickle', 'rb'))  # the data\n",
        "test_labels = pickle.load(open('y_val.pickle', 'rb'))  # labels for each data\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJs0MTyG-Mlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_BsOpOTr5uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scvqR08fut6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR_EVAL = \"/content/drive/My Drive/PseudoDataReal\"\n",
        "\n",
        "evaluation_data = []\n",
        "\n",
        "def create_evaluation_data():\n",
        "  for category in CATEGORIES:  \n",
        "    path = os.path.join(DATADIR_EVAL,category)  \n",
        "    class_num = CATEGORIES.index(category)  # if 0, type 1 data; 1, type 2 data; 2, type 3 data. \n",
        "    for img in os.listdir(path):  \n",
        "        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "        evaluation_data.append([new_array, class_num])\n",
        "\n",
        "create_evaluation_data()\n",
        "\n",
        "print(len(evaluation_data))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX5kKn8t3r-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_eval = []\n",
        "y_eval = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp9VSfCf3vnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(evaluation_data)\n",
        "\n",
        "for features, label in evaluation_data:\n",
        "  X_eval.append(features)\n",
        "  y_eval.append(label)\n",
        "\n",
        "X_eval = np.array(X_eval).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "X_eval = X_eval/255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLLH49et5Dmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_eval,  y_eval, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}